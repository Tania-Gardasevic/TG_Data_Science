{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Analysis after running CPPTRAJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary python modules for notebook - including handling data, plots and statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMPBSA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative averages and EXP values have been saved to MMPBSA_avg.csv\n"
     ]
    }
   ],
   "source": [
    "#### Function to load and process data with normalisation ####\n",
    "# Read in filename, name of data, reference column for normalisation and if the data is the experimental\n",
    "# Default values for reference column and is_exp set as None and False\n",
    "def load_and_process_data(filename, dataname, reference_col=None, is_exp=False):\n",
    "    # Read data, with 'run' as index for the computational data (experimental does not have run column)\n",
    "    data = pd.read_csv(filename, index_col=0) if not is_exp else pd.read_csv(filename)\n",
    "\n",
    "    # Experimental data is already normalized and does not require further processing, data returned as it is\n",
    "    if is_exp:\n",
    "        return data\n",
    "    \n",
    "    # Select only numeric columns for averaging\n",
    "    numeric_data = data.select_dtypes(include=[float, int])  \n",
    "    # Calculate averages across each column (protein)\n",
    "    averages = numeric_data.mean(axis=0)\n",
    "    # Calculate standard deviation for each column (protein)\n",
    "    std_dev = numeric_data.std(axis=0)\n",
    "    # Normalise data based on the reference column\n",
    "    relative_averages = averages - averages[reference_col]\n",
    "    \n",
    "    # Return normalised data and standard deviations\n",
    "    return pd.DataFrame({\n",
    "            'protein': averages.index,\n",
    "            dataname: relative_averages.values,\n",
    "            f'{dataname}_std': std_dev.values\n",
    "        })\n",
    "    \n",
    "#### Function to merge each data frame together ####\n",
    "# Read in the computational and experimental dataframes\n",
    "def merge_data_frames(df1, df2, dfexp):\n",
    "    # Merge the computational dataframes on 'protein'\n",
    "    merged = pd.merge(df1, df2, on='protein', how='outer')\n",
    "    # Merge with experimentla dataframe\n",
    "    merged = pd.merge(merged, dfexp, on='protein', how='outer')\n",
    "    \n",
    "    # Return merged dataframe \n",
    "    return merged\n",
    "\n",
    "#### Define file name and data name for each computational data set and for the experimental data ####\n",
    "# Sample data: HMR and Standard\n",
    "name1 = 'HMR'\n",
    "file_data1 = f\"{name1}_MMPBSA.csv\"\n",
    "name2 = 'Standard'\n",
    "file_data2 = f\"{name2}_MMPBSA.csv\"\n",
    "name_exp = 'EXP'\n",
    "file_exp = f\"{name_exp}_data.csv\"\n",
    "combined_data_file = 'MMPBSA_avg'\n",
    "\n",
    "#### Read in and process data ####\n",
    "# Sample data: data1 = HMR, data2 = Standard, normalised to wildtype ('W')\n",
    "data1 = load_and_process_data(file_data1, name1, reference_col='W')\n",
    "data2 = load_and_process_data(file_data2, name2, reference_col='W')\n",
    "\n",
    "# Read EXP data (no normalisation or averaging needed)\n",
    "data_exp = load_and_process_data(file_exp, name_exp, is_exp=True)\n",
    "\n",
    "#### Merge all data into one dataframe ####\n",
    "final_df = merge_data_frames(data1, data2, data_exp)\n",
    "\n",
    "#### Save the merged dataframe to a new CSV file ####\n",
    "final_df.to_csv(f\"{combined_data_file}.csv\", index=False)\n",
    "\n",
    "#### Print message indicating new saved csv file ####\n",
    "print(f\"Relative averages and EXP values have been saved to MMPBSA_avg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MMPBSA Data with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Initialise linear regression model ####\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "#### Function to load in the combined dataframe ####\n",
    "def load_data(data_file):\n",
    "    # Set index of dataframe as 'protein'\n",
    "    data = pd.read_csv(f\"{data_file}.csv\", header=0, sep=\",\").set_index(\"protein\")\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data\n",
    "\n",
    "#### Function to define a colour map for a certain number of points ####\n",
    "def define_colormap(num_points):\n",
    "    # Assign predefined colour map 'inferno' to palet\n",
    "    palet = plt.cm.inferno\n",
    "    # Take 90% of colour map to avoid light yellow part that does not appear well on plot\n",
    "        # Generates 256 evenly spaced values between 0 and 0.9 to subset the colour map\n",
    "    truncated_palet = LinearSegmentedColormap.from_list(\n",
    "        'truncated_palet', palet(np.linspace(0, 0.9, 256))\n",
    "    )\n",
    "    # Return colours evenly spaced in truncated_palet corresponding to the number of points\n",
    "    return truncated_palet(np.linspace(0, 1, num_points))\n",
    "\n",
    "#### Function to plot computational vs experimental data, with linear regression ####\n",
    "# Read in the axes number, data, data name, colours and plot title\n",
    "def plot_data(ax, data, dataname, colors, title):\n",
    "    \n",
    "    # Define x and y data as computational and experimental data\n",
    "    x = np.array(data[dataname]).reshape(-1, 1) \n",
    "    y = np.array(data[\"EXP\"]).reshape(-1, 1)\n",
    "    \n",
    "    # Fit linear regression to the x and y data\n",
    "    regr.fit(x, y)\n",
    "    # Plot regression line\n",
    "    ax.plot(x, regr.coef_ * x + regr.intercept_, color=\"black\")\n",
    "\n",
    "    # Scatter plot of data with error bars of standard deviation, assigning specifical colour to each protein\n",
    "    for i, (comp, exp, std, color) in enumerate(zip(data[dataname], data[\"EXP\"], data[f\"{dataname}_std\"], colors)):\n",
    "        ax.scatter(comp, exp, color=color)\n",
    "        ax.errorbar(comp, exp, xerr=std, fmt='o', color=color, capsize=4)\n",
    "\n",
    "    # Calculate Pearson's r ('_' used as placeholder for p-value which is not used here)\n",
    "    pearson_r, _ = pearsonr(data[dataname], data[\"EXP\"])\n",
    "    # \n",
    "    ax.text(\n",
    "        # Coordinates to position text box at top left of plot\n",
    "        0.05, 0.95, \n",
    "        # Print Pearson's r value, slope and intercept of regression line\n",
    "        f\"r: {pearson_r:.4f}\\nSlope: {regr.coef_[0][0]:.4f}\\nIntercept: {regr.intercept_[0]:.4f}\", \n",
    "        # Use coordinates as relative to figure (0.05 = 5% from left, 0.95 = 95% from bottom), define font and exact position\n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "        # Create box around text for easier visualisation\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\")\n",
    "    )\n",
    "    # Display title of plot\n",
    "    ax.set_title(title)\n",
    "    # Display x-axis of plot\n",
    "    ax.set_xlabel(\"\\u0394\\u0394G Computational (Kcal mol \\u207B\\u00B9)\")\n",
    "\n",
    "#### Set up plot to contain two subplots that share the same y-axis dimensions ####\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "\n",
    "#### Retreive combined data file name and computational data names from previous notebook cell ####\n",
    "# Try block used to raise error if notebook is run out of order\n",
    "try:\n",
    "    # Assuming 'combined_data_file', 'name1', and 'name2' are defined in previous notebook cell:\n",
    "    combined_data_file, name1, name2\n",
    "    # Print message to show data has been retrieved\n",
    "    print(f\"Using data file: {combined_data_file} for {name1} and {name2}\")\n",
    "\n",
    "# Raise error suggesting notebook should be run in order\n",
    "except NameError as e:\n",
    "    print(f\"Error: One or more variables are not defined. Try running the whole notebook in order. Details: {e}\")\n",
    "    raise\n",
    "\n",
    "#### Load the combined dataframe ####\n",
    "data = load_data(combined_data_file)\n",
    "\n",
    "#### Define colors for plotting using number of data points in loaded data ####\n",
    "colors = define_colormap(len(data.index))\n",
    "\n",
    "#### Plot datasets ####\n",
    "# Sample data: HMR, plotted on 1st subplot\n",
    "plot_data(ax[0], data, name1, colors, \"MMPBSA HMR MD\")\n",
    "# Sample data: Standard, plotted on 2nd subplot\n",
    "plot_data(ax[1], data, name2, colors, \"MMPBSA Standard MD\")\n",
    "\n",
    "# Display y-axis for 1st subplot\n",
    "ax[0].set_ylabel(\"\\u0394\\u0394G Experimental (Kcal mol \\u207B\\u00B9)\")\n",
    "# Display y-axis ticks for 2nd subplot for easier visualisation\n",
    "ax[1].tick_params(axis='y', which='both', labelleft=True)\n",
    "\n",
    "#### Add legend ####\n",
    "# Create 'fake' line to be used to create legend, with colors matching previous plots and labels taken from data index column (protein label)\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker='o', color=color, linestyle='', label=f\"{label}\") \n",
    "    for label, color in zip(data.index, colors)\n",
    "]\n",
    "# Plot legend in bottom left with outline box and title 'Protein', reversing order to better match distribution of points in plot\n",
    "fig.legend(handles=handles[::-1], loc='center left', bbox_to_anchor=(1.05, 0.5), title=\"Protein\")\n",
    "\n",
    "#### Format and save final plot ####\n",
    "# Set x-axis tick range for both plots\n",
    "for a in ax:\n",
    "    a.set_xticks(range(-15, 6, 5))\n",
    "# Ensure all elements of plots fit in the space without overlapping\n",
    "plt.tight_layout()\n",
    "# Save final plot figure with white background, removing any extra white space and at 300 dpi\n",
    "fig.savefig(\"MMPBSA.png\", dpi=300, bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Display Statistics Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to calculate statistics metrics ####\n",
    "def calculate_metrics(data, name):\n",
    "    # Calculate Pearson's r and p-value\n",
    "    pearson_r, r_p_value = pearsonr(data[name], data[\"EXP\"])\n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(data[\"EXP\"], data[name]))\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(data[\"EXP\"], data[name])\n",
    "    # Calculate mean of standard deviations\n",
    "    mean_std = data[f\"{name}_std\"].mean()\n",
    "    # Calculate t-statistic and p-value for paired t-test (assuming equal variance)\n",
    "    t_stat, t_p_value = ttest_rel(data[\"EXP\"], data[name])\n",
    "    \n",
    "    # Return all statistics metrics\n",
    "    return pearson_r, r_p_value, rmse, mae, mean_std, t_stat, t_p_value\n",
    "\n",
    "#### Retreive combined data file and computational data names from previous notebook cell ####\n",
    "# Try block used to raise error if notebook is run out of order\n",
    "try:\n",
    "    # Assuming 'combined_data_file', 'name1', and 'name2' are defined in previous notebook cell:\n",
    "    combined_data_file, data, name1, name2\n",
    "    # Print message to show data has been retrieved\n",
    "    print(f\"Using data file: {combined_data_file} for {name1} and {name2}\")\n",
    "\n",
    "# Raise error suggesting notebook should be run in order\n",
    "except NameError as e:\n",
    "    print(f\"Error: One or more variables are not defined. Try running the whole notebook in order. Details: {e}\")\n",
    "    raise\n",
    "\n",
    "#### Calculate metrics for name1 and name2 ####\n",
    "# Sample data: name1 = HMR, name2 = Standard\n",
    "name1_metrics = calculate_metrics(data, name1)\n",
    "name2_metrics = calculate_metrics(data, name2)\n",
    "\n",
    "#### Create a dataframe with name1 and name2 as columns, setting statistics metrics as index ####\n",
    "# Sample data: name1 = HMR, name2 = Standard\n",
    "df_results = pd.DataFrame({\n",
    "    name1: name1_metrics,\n",
    "    name2: name2_metrics\n",
    "}, index=[\"Pearson's r:\", \"p-value:\" ,\"RMSE:\", \"MAE:\", \"Mean STD:\", \"t-statistic:\", \"p-value:\"])\n",
    "\n",
    "#### Print and save the dataframe ####\n",
    "print(df_results)\n",
    "df_results.to_csv(\"MMPBSA_metrics.csv\", index_label=\"Metric\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
